{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0146f1718ad0e3d",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": "%pip install -q lightning wandb torchvision torchmetrics matplotlib",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3a61bb54bd1e4127",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "id": "ab3704f5552bc610",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import PIL.Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms.v2 as v2\n",
    "import torchmetrics\n",
    "import lightning as L\n",
    "import wandb\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from jassair.utils import get_dataset_path, Datasets"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6dd49b83-0cb1-47d1-902a-bcebd5c6bed3",
   "metadata": {},
   "source": [
    "## Lower matmul precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18fd5d29ce9df92",
   "metadata": {},
   "source": [
    "## WandB login for experiment tracking"
   ]
  },
  {
   "cell_type": "code",
   "id": "6fae3a0e117edec1",
   "metadata": {},
   "source": [
    "wandb.login()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bc4e6fbb2bfab8d1",
   "metadata": {},
   "source": [
    "## Global variable definition"
   ]
  },
  {
   "cell_type": "code",
   "id": "ec831c9c5322ffc8",
   "metadata": {},
   "source": [
    "DATA_DIR = get_dataset_path(Datasets.S_1TO1_36C_NOVLP)\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 36"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "85f97c9f3a81ba34",
   "metadata": {},
   "source": [
    "## Custom Synth-data Dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "f2457dd9e76a10e7",
   "metadata": {},
   "source": [
    "class YoloStyleDataset(Dataset):\n",
    "    def __init__(self, root_dir: Path, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_dir = root_dir / 'images'\n",
    "        self.label_dir = root_dir / 'labels'\n",
    "        self.transform = transform\n",
    "        self.image_files: list[Path] = [f for f in self.image_dir.iterdir()]\n",
    "        self.labels: list[int] = []\n",
    "        for file in self.image_files:\n",
    "            label_file = self.label_dir / f\"{file.stem}.txt\"\n",
    "            with label_file.open(\"r\", encoding=\"utf-8\") as f:\n",
    "                self.labels.append(int(f.readline().split()[0]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path: Path = self.image_files[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = PIL.Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "716edaa5ec6aea34",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "id": "8e1e262cca21eb8d",
   "metadata": {},
   "source": [
    "class ImageClassifier(L.LightningModule):\n",
    "    def __init__(self, lr: float, weight_decay: float, finetune_only: bool):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.model = MODEL\n",
    "        \n",
    "        # If set, only train the newly attached FC layer\n",
    "        if self.hparams.finetune_only:\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        match self.model._get_name().lower():\n",
    "            case \"efficientnet\":\n",
    "                in_features = self.model.classifier[1].in_features\n",
    "                self.model.classifier[1] = nn.Linear(in_features, NUM_CLASSES)\n",
    "            case \"resnet\":\n",
    "                in_features = self.model.fc.in_features\n",
    "                self.model.fc = nn.Linear(in_features, NUM_CLASSES)\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self._train_acc = torchmetrics.Accuracy(\"multiclass\", num_classes=NUM_CLASSES)\n",
    "        self._train_loss = []\n",
    "        self._valid_acc = torchmetrics.Accuracy(\"multiclass\", num_classes=NUM_CLASSES)\n",
    "        self._valid_loss = []\n",
    "        self._test_preds = []\n",
    "        self._test_labels = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self._train_acc(outputs, labels)\n",
    "        self._train_loss.append(loss)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self._valid_acc(outputs, labels)\n",
    "        self._valid_loss.append(loss)\n",
    "        \n",
    "    def on_train_epoch_end(self):\n",
    "        loss = torch.stack(self._train_loss).mean()\n",
    "        self.log_dict({'train_loss': loss, 'train_acc': self._train_acc.compute()}, prog_bar=True)\n",
    "        self._train_loss.clear()\n",
    "        self._train_acc.reset()\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        loss = torch.stack(self._valid_loss).mean()\n",
    "        self.log_dict({'val_loss': loss, 'val_acc': self._valid_acc.compute()}, prog_bar=True)\n",
    "        self._valid_loss.clear()\n",
    "        self._valid_acc.reset()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        self._test_preds.append(preds.detach().cpu())\n",
    "        self._test_labels.append(y.detach().cpu())\n",
    "\n",
    "        return {}\n",
    "\n",
    "    def test_epoch_end(self):\n",
    "        preds = torch.cat(self._test_preds)\n",
    "        targets = torch.cat(self._test_labels)\n",
    "\n",
    "        cm = self._confusion_matrix(preds, targets)\n",
    "\n",
    "        precision = []\n",
    "        recall = []\n",
    "        f1 = []\n",
    "\n",
    "        for i in range(self.num_classes):\n",
    "            true_positives = cm[i, i].item()\n",
    "            false_positives = cm[:, i].sum().item() - true_positives\n",
    "            false_negatives = cm[i, :].sum().item() - true_positives\n",
    "\n",
    "            _precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0.0\n",
    "            _recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0.0\n",
    "            _f1 = 2 * _precision * _recall / (_precision + _recall) if (_precision + _recall) > 0 else 0.0\n",
    "\n",
    "            precision.append(_precision)\n",
    "            recall.append(_recall)\n",
    "            f1.append(_f1)\n",
    "\n",
    "            self.log(f'test/precision_class_{i}', _precision)\n",
    "            self.log(f'test/recall_class_{i}', _recall)\n",
    "            self.log(f'test/f1_class_{i}', _f1)\n",
    "\n",
    "        # Overall Accuracy\n",
    "        acc = (preds == targets).sum().item() / len(targets)\n",
    "        self.log('test/accuracy', acc)\n",
    "\n",
    "        # Macro averages\n",
    "        self.log('test/macro_precision', sum(precision) / self.num_classes)\n",
    "        self.log('test/macro_recall', sum(recall) / self.num_classes)\n",
    "        self.log('test/macro_f1', sum(f1) / self.num_classes)\n",
    "\n",
    "    def _confusion_matrix(self, preds, targets):\n",
    "        cm = torch.zeros(self.num_classes, self.num_classes, dtype=torch.int32)\n",
    "        for t, p in zip(targets, preds):\n",
    "            cm[t, p] += 1\n",
    "        return cm\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)\n",
    "        scheduler = optim.lr_scheduler.CyclicLR(optimizer, self.hparams.lr / 1000, self.hparams.lr)\n",
    "        return [optimizer], [scheduler]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "de25a48a-4b6c-4789-82d5-bf38bddeddf9",
   "metadata": {},
   "source": [
    "#### Training routine"
   ]
  },
  {
   "cell_type": "code",
   "id": "a0ec5c8b-33c5-4a0c-9302-447338804061",
   "metadata": {},
   "source": [
    "def get_run_name(config, ft=False):\n",
    "    params = []\n",
    "    for k, v in config.items():\n",
    "        if isinstance(v, float):\n",
    "            params.append(f\"{k}{v:.4f}\")\n",
    "        else:\n",
    "            params.append(f\"{k}{v}\")\n",
    "    return f\"{MODEL_NAME}_{'_'.join(params)}_ft{ft}{time.strftime('%y%m%d%H%M%S')}\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "57a3252c-6bf2-4299-9cc4-6f33d9f1f1dd",
   "metadata": {},
   "source": [
    "def train_classifier(config, logger, *callbacks):\n",
    "    L.seed_everything(42)\n",
    "    model = ImageClassifier(\n",
    "        wandb.config.get(\"lr\"), \n",
    "        wandb.config.get(\"wd\"),\n",
    "        wandb.config.get(\"ft_only\"),\n",
    "    )\n",
    "    trainer = L.Trainer(\n",
    "        callbacks=list(callbacks),\n",
    "        max_epochs=wandb.config.get(\"epochs\"),\n",
    "        accelerator=\"auto\",\n",
    "        precision='16-mixed',\n",
    "        logger=logger,\n",
    "    )\n",
    "    trainer.fit(model, train_loader, val_loader)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4db868c3-55bb-45a0-968b-99222ae624b9",
   "metadata": {},
   "source": [
    "def wandb_train_run(run):\n",
    "    config = wandb.config\n",
    "    run.name = get_run_name(config)\n",
    "    checkpoint_callback = L.pytorch.callbacks.ModelCheckpoint(\n",
    "        dirpath=\"./lightning_checkpoints\",\n",
    "        filename=run.name + \"_{epoch:02d}_{val_acc:.2f}\",\n",
    "        monitor=\"val_acc\",\n",
    "        save_last=True,\n",
    "        mode=\"max\"\n",
    "    )\n",
    "    early_stopping_callback = L.pytorch.callbacks.EarlyStopping(\n",
    "        min_delta=0.005, # Improve at least 0.5%\n",
    "        monitor=\"val_acc\",\n",
    "        patience=5,\n",
    "        mode=\"max\",\n",
    "    )\n",
    "    wandb_logger = WandbLogger()\n",
    "    train_classifier(config, wandb_logger, checkpoint_callback, early_stopping_callback)\n",
    "    artifact = wandb.Artifact(run.name, \"model\")\n",
    "    artifact.add_file(checkpoint_callback.best_model_path)\n",
    "    wandb.log_artifact(artifact)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_cm(predictions, labels, name):\n",
    "    cm = torchmetrics.ConfusionMatrix(\"multiclass\", num_classes=5)\n",
    "    cm.update(predictions, labels)\n",
    "    fig, ax = cm.plot(labels=[\"A\", \"B\", \"C\", \"D\", \"E\"], cmap=\"plasma\")\n",
    "    cbar = fig.colorbar(ax.images[0], ax=ax)\n",
    "    plt.savefig(f\"{name}.png\", bbox_inches='tight')"
   ],
   "id": "d9ab94fe3aa89c82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def test_classifier(checkpoint, logger, name):\n",
    "    L.seed_everything(42)\n",
    "    model = ImageClassifier.load_from_checkpoint(checkpoint)\n",
    "    trainer = L.Trainer(\n",
    "        accelerator=\"auto\",\n",
    "        logger=logger,\n",
    "    )\n",
    "    trainer.test(model, test_loader)\n",
    "    plot_cm(model._test_preds, model._test_labels, name)"
   ],
   "id": "367fea4560f13eaf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def wandb_test_run(run, checkpoint):\n",
    "    config = wandb.config\n",
    "    run.name = get_run_name(config)\n",
    "    wandb_logger = WandbLogger()\n",
    "    test_classifier(checkpoint, wandb_logger, run.name)"
   ],
   "id": "ebb895552cbf3bc9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "389e5e54-2efa-49c3-b322-b058ab03085e",
   "metadata": {},
   "source": [
    "def classifier_sweep(config=None):\n",
    "    with wandb.init(config=config) as run:\n",
    "        wandb_train_run(run)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7ede355de15d3f42",
   "metadata": {},
   "source": [
    "## EfficientNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87985efc-bd8b-4926-a75b-eef3b17dcf26",
   "metadata": {},
   "source": [
    "#### Load model and weights"
   ]
  },
  {
   "cell_type": "code",
   "id": "debea0f2-21d6-4890-b131-976141fd28ff",
   "metadata": {},
   "source": [
    "MODEL_WEIGHTS = models.EfficientNet_V2_S_Weights.IMAGENET1K_V1\n",
    "TRANSFORM = MODEL_WEIGHTS.transforms()\n",
    "MODEL = models.efficientnet_v2_s(weights=MODEL_WEIGHTS)\n",
    "MODEL_NAME = MODEL._get_name()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1cf40a96-02e3-42c9-80e5-34acc82afa3c",
   "metadata": {},
   "source": [
    "print(f\"TRANSFORM: {TRANSFORM}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9535a01e-db3d-4dc1-a9ae-01b4ad214b80",
   "metadata": {},
   "source": [
    "#### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "id": "9229906a-a363-496e-b3d8-8181db0e959e",
   "metadata": {},
   "source": [
    "transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.RandomAffine(degrees=180, translate=(0.1, 0.1)),\n",
    "    v2.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "    v2.Resize(384, interpolation=v2.InterpolationMode.BILINEAR),\n",
    "    v2.ToDtype(torch.float32, scale=True),  # Converts to float [0,1]\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                 std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "print(transform)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9ce742aa-196f-4abe-aa1d-a46c2b5a4b65",
   "metadata": {},
   "source": [
    "#### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "id": "4d6298b7-cdc5-4cef-ad1c-98e06805f577",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "train_dataset = YoloStyleDataset(DATA_DIR / \"train\", transform)\n",
    "val_dataset = YoloStyleDataset(DATA_DIR / \"valid\", TRANSFORM)\n",
    "test_dataset = YoloStyleDataset(DATA_DIR / \"test\", TRANSFORM)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8, persistent_workers=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "\n",
    "# Sanity check\n",
    "image, label = next(iter(test_loader))\n",
    "print(f\"Test Image shape: {image.shape}, Label: {label.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fb5ea731-a5e2-4c7e-bf1f-b6886cc385de",
   "metadata": {},
   "source": [
    "## Test run"
   ]
  },
  {
   "cell_type": "code",
   "id": "00bab53d-f347-44fb-afb8-8acb31b4c087",
   "metadata": {},
   "source": [
    "with wandb.init(\n",
    "    entity=\"jassair\",\n",
    "    project=\"Baseline\",\n",
    "    config={\n",
    "        \"lr\": 1e-2,\n",
    "        \"wd\": 1e-6,\n",
    "        \"ft_only\": True,\n",
    "        \"epochs\": 50\n",
    "    },\n",
    ") as run:\n",
    "    wandb_train_run(run)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "30a6f26f-ecef-47b0-91ec-89fb49cfa44e",
   "metadata": {},
   "source": [
    "## Hyperparameter Sweep"
   ]
  },
  {
   "cell_type": "code",
   "id": "86f46b72-b432-4355-857e-7bc368596f4c",
   "metadata": {},
   "source": [
    "sweep_config = {\n",
    "    \"name\": \"EffiecientNet-Sweep\",\n",
    "    \"method\": \"grid\",\n",
    "    \"metric\": {\"name\": \"val_acc\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"lr\": {\"values\": [1e-3, 1e-2]},\n",
    "        \"wd\": {\"values\": [1e-6, 1e-5, 1e-4]},\n",
    "        \"ft_only\": {\"value\": True},\n",
    "        \"epochs\": {\"value\": 50},\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2d70d0ad-99a0-4115-a28f-e754ea5158a5",
   "metadata": {},
   "source": [
    "sweep_id = wandb.sweep(\n",
    "    sweep=sweep_config, \n",
    "    entity=\"jassair\",\n",
    "    project=\"BaselineModel\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3a380682-c033-4fb9-b8ab-d98ce01e84e7",
   "metadata": {},
   "source": "wandb.agent(sweep_id=sweep_id, function=classifier_sweep)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c255866c-8623-42b5-8f0a-71c3e5edbc92",
   "metadata": {},
   "source": [
    "wandb.api.stop_sweep(sweep_id)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "398e4dd6-2b98-494b-861e-bab63ea9ed6a",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39737ad3-ff3d-4d61-a669-8e5774d3d9f5",
   "metadata": {},
   "source": [
    "#### Load model and weights"
   ]
  },
  {
   "cell_type": "code",
   "id": "9718ceb2-1454-48fa-92a4-da07309b9871",
   "metadata": {},
   "source": [
    "MODEL_WEIGHTS = models.ResNet50_Weights.IMAGENET1K_V2\n",
    "TRANSFORM = MODEL_WEIGHTS.transforms()\n",
    "MODEL = models.resnet50(weights=MODEL_WEIGHTS)\n",
    "MODEL_NAME = MODEL._get_name()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7da60bb9-726a-418c-b42d-b2276f4a5953",
   "metadata": {},
   "source": [
    "print(f\"TRANSFORM: {TRANSFORM}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a15d1470-35d1-4895-89ca-88a75b975526",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "id": "9858c96b-1eb9-4fa6-82da-729398939aed",
   "metadata": {},
   "source": [
    "transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "    v2.Resize(232, interpolation=v2.InterpolationMode.BILINEAR),\n",
    "    v2.ToDtype(torch.float32, scale=True),  # Converts to float [0,1]\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                 std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "print(transform)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "88889b25-1ea7-4a86-86da-a1604135dde6",
   "metadata": {},
   "source": [
    "#### Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "id": "3c67284e-fc79-4860-811f-b5b773c69a98",
   "metadata": {},
   "source": [
    "train_dataset = YoloStyleDataset(DATA_DIR / \"train\", transform=transform)\n",
    "val_dataset = YoloStyleDataset(DATA_DIR / \"valid\", transform=TRANSFORM)\n",
    "test_dataset = YoloStyleDataset(DATA_DIR / \"test\", transform=TRANSFORM)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=16, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=16, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=16, pin_memory=True)\n",
    "\n",
    "# Sanity check\n",
    "image, label = train_dataset[1]\n",
    "print(f\"Train Image shape: {image.shape}, Label: {label}\")\n",
    "image, label = test_dataset[1]\n",
    "print(f\"Test Image shape: {image.shape}, Label: {label}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "56bfa86b-ccf3-4b44-8f3c-6974c99e62db",
   "metadata": {},
   "source": [
    "sweep_config = {\n",
    "    \"name\": \"ResNet-Sweep\",\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"name\": \"val_acc\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"lr\": {\"values\": [1e-4, 1e-3, 1e-2]},\n",
    "        \"wd\": {\"values\": [1e-6, 1e-5, 1e-4]},\n",
    "        \"ft_only\": {\"values\": [True, False]},\n",
    "        \"epochs\": {\"value\": 50},\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e2948649-e222-49f8-8b34-c1a3256cfd3b",
   "metadata": {},
   "source": [
    "sweep_id = wandb.sweep(\n",
    "    sweep=sweep_config, \n",
    "    entity=\"jassair\",\n",
    "    project=\"BaselineModel\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5b6110bf-91ba-4425-af29-a80e6e2887fc",
   "metadata": {},
   "source": [
    "wandb.agent(sweep_id=sweep_id, function=classifier_sweep, count=6)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8378d764-c651-4572-bb8d-bccfdd518741",
   "metadata": {},
   "source": [
    "wandb.api.stop_sweep(sweep_id)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluation",
   "id": "80b98a72d9579fab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def run_tests(cps: list[str], test_set: str):\n",
    "    for checkpoint in cps:\n",
    "        with wandb.init(entity=\"jassair\", project=\"BaselineModel\", config=dict(test=test_set)) as run:\n",
    "            wandb_test_run(run, checkpoint)"
   ],
   "id": "83ce0e1bedcfe034",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### ResNet",
   "id": "1ba5058faccce9d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "MODEL_WEIGHTS = models.ResNet50_Weights.IMAGENET1K_V2\n",
    "TRANSFORM = MODEL_WEIGHTS.transforms()\n",
    "MODEL = models.resnet50(weights=MODEL_WEIGHTS)\n",
    "MODEL_NAME = MODEL._get_name()"
   ],
   "id": "6cb86554892ceb67",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "checkpoints = [\n",
    "    \n",
    "]"
   ],
   "id": "9a38496b839c1891",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Synthetic data",
   "id": "9f48966e76bec69d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_dataset = YoloStyleDataset(get_dataset_path(Datasets.S_1TO1_36C_NOVLP) / \"test\")\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)"
   ],
   "id": "fe2eee2d1d21255d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "run_tests(checkpoints, \"synth\")",
   "id": "52498195ad1d7177",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Real world data",
   "id": "b238632d1c512c3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_dataset = YoloStyleDataset(get_dataset_path(Datasets.R_1TO1_36C_NOVLP) / \"test\")\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)"
   ],
   "id": "8eff8d58195ec946",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "run_tests(checkpoints, \"real\")",
   "id": "116b374636ba27d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### EfficientNet",
   "id": "daca27048e87affd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "MODEL_WEIGHTS = models.EfficientNet_V2_S_Weights.IMAGENET1K_V1\n",
    "TRANSFORM = MODEL_WEIGHTS.transforms()\n",
    "MODEL = models.efficientnet_v2_s(weights=MODEL_WEIGHTS)\n",
    "MODEL_NAME = MODEL._get_name()"
   ],
   "id": "bc5b60e28a9b7cff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "checkpoints = [\n",
    "    \n",
    "]"
   ],
   "id": "d219b083f554d7ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Synthetic Data",
   "id": "41b333b0a22059da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_dataset = YoloStyleDataset(get_dataset_path(Datasets.S_1TO1_36C_NOVLP) / \"test\")\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)"
   ],
   "id": "e9465e3f6a61afb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "run_tests(checkpoints, \"synth\")",
   "id": "7acb76d3ccffcf49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Real data",
   "id": "7166b9ace6c0d589"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_dataset = YoloStyleDataset(get_dataset_path(Datasets.R_1TO1_36C_NOVLP) / \"test\")\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)"
   ],
   "id": "ec16962270e175c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "run_tests(checkpoints, \"real\")",
   "id": "904516117816672c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
