{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0146f1718ad0e3d",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T09:42:22.722459Z",
     "start_time": "2025-03-26T09:42:17.847820Z"
    }
   },
   "source": "%pip install -q lightning wandb torchvision torchmetrics",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "3a61bb54bd1e4127",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab3704f5552bc610",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T19:06:58.051572Z",
     "start_time": "2025-03-25T19:06:58.040118Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import PIL.Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchmetrics\n",
    "import lightning as L\n",
    "import wandb\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "from jassair.utils import get_dataset_path, Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd49b83-0cb1-47d1-902a-bcebd5c6bed3",
   "metadata": {},
   "source": [
    "## Lower matmul precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad3f0cd3-5eff-49b9-8579-7010b92933b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "L.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18fd5d29ce9df92",
   "metadata": {},
   "source": [
    "## WandB login for experiment tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fae3a0e117edec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4e6fbb2bfab8d1",
   "metadata": {},
   "source": [
    "## Global variable definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec831c9c5322ffc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T19:06:58.336041Z",
     "start_time": "2025-03-25T19:06:58.327493Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = get_dataset_path(Datasets.SYNTHETIC_SINGLE)\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 36"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f97c9f3a81ba34",
   "metadata": {},
   "source": [
    "## Custom Synth-data Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2457dd9e76a10e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T19:10:23.835755Z",
     "start_time": "2025-03-25T19:10:23.815333Z"
    }
   },
   "outputs": [],
   "source": [
    "class YoloStyleDataset(Dataset):\n",
    "    def __init__(self, root_dir: Path, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_dir = root_dir / 'images'\n",
    "        self.label_dir = root_dir / 'labels'\n",
    "        self.transform = transform\n",
    "        self.image_files: list[Path] = [f for f in self.image_dir.iterdir()]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path: Path = self.image_files[idx]\n",
    "        image = PIL.Image.open(image_path).convert(\"RGB\")\n",
    "        label_path = self.label_dir / f\"{image_path.stem}.txt\"\n",
    "        if not label_path.exists():\n",
    "            raise FileNotFoundError(label_path)\n",
    "        with label_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "            label = int(f.readline().split()[0])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b8efc9fa34e605",
   "metadata": {},
   "source": [
    "## Pre-trained Model / Data transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83bfcea328dfa19d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T19:31:41.894301Z",
     "start_time": "2025-03-25T19:31:41.125969Z"
    }
   },
   "outputs": [],
   "source": [
    "# Available models: https://pytorch.org/vision/stable/models.html#classification\n",
    "\n",
    "MODEL_WEIGHTS = models.ResNet50_Weights.IMAGENET1K_V2\n",
    "TRANSFORM = MODEL_WEIGHTS.transforms()\n",
    "MODEL = models.resnet50(weights=MODEL_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00af6bf9b9f2135",
   "metadata": {},
   "source": [
    "## DataLoader definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18ee610675a48977",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T19:17:36.224419Z",
     "start_time": "2025-03-25T19:17:36.189486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([3, 224, 224]), Label: 29\n"
     ]
    }
   ],
   "source": [
    "train_dataset = YoloStyleDataset(DATA_DIR / \"train\", transform=TRANSFORM)\n",
    "val_dataset = YoloStyleDataset(DATA_DIR / \"valid\", transform=TRANSFORM)\n",
    "test_dataset = YoloStyleDataset(DATA_DIR / \"test\", transform=TRANSFORM)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "# Sanity check\n",
    "image, label = train_dataset[1]\n",
    "print(f\"Image shape: {image.shape}, Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716edaa5ec6aea34",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e1e262cca21eb8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T19:31:00.664550Z",
     "start_time": "2025-03-25T19:31:00.650788Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageClassifier(L.LightningModule):\n",
    "    def __init__(self, lr: float, weight_decay: float, finetune_only: bool):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.model = MODEL\n",
    "        \n",
    "        # If set, only train the newly attached FC layer\n",
    "        if self.hparams.finetune_only:\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "                \n",
    "        in_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(in_features, NUM_CLASSES)\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self._train_acc = torchmetrics.Accuracy(\"multiclass\", num_classes=self.hparams.output_dim)\n",
    "        self._train_loss = []\n",
    "        self._valid_acc = torchmetrics.Accuracy(\"multiclass\", num_classes=self.hparams.output_dim)\n",
    "        self._valid_loss = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self._train_acc(outputs, labels)\n",
    "        self._train_loss.append(loss)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self._valid_acc(outputs, labels)\n",
    "        self._valid_loss.append(loss)\n",
    "        \n",
    "    def on_train_epoch_end(self):\n",
    "        loss = torch.stack(self._train_loss).mean()\n",
    "        self.log_dict({'train_loss': loss, 'train_acc': self._train_acc.compute()}, prog_bar=True)\n",
    "        self._train_loss.clear()\n",
    "        self._train_acc.reset()\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        loss = torch.stack(self._valid_loss).mean()\n",
    "        self.log_dict({'val_loss': loss, 'val_acc': self._valid_acc.compute()}, prog_bar=True)\n",
    "        self._valid_loss.clear()\n",
    "        self._valid_acc.reset()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        acc = (outputs.argmax(dim=1) == labels).float().mean()\n",
    "        \n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "        self.log(\"test_acc\", acc, prog_bar=True, logger=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)\n",
    "        scheduler = optim.lr_scheduler.CyclicLR(optimizer, self.hparams.lr / 100, self.hparams.lr)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ede355de15d3f42",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22ac9b784071073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPERPARAMETERS = {\n",
    "    \"lr\": 1e-3,\n",
    "    \"wd\": 1e-5,\n",
    "    \"ft_only\": True,\n",
    "    \"epochs\": 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fae4937e17f8c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/DSPRO2-jassAIr/wandb/run-20250325_202121-o26qz607</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jassair/BaselineModel/runs/o26qz607' target=\"_blank\">250325-202121_ResNet_lr0.0001</a></strong> to <a href='https://wandb.ai/jassair/BaselineModel' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jassair/BaselineModel' target=\"_blank\">https://wandb.ai/jassair/BaselineModel</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jassair/BaselineModel/runs/o26qz607' target=\"_blank\">https://wandb.ai/jassair/BaselineModel/runs/o26qz607</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RUN_NAME = f\"{time.strftime('%y%m%d-%H%M%S')}_{MODEL._get_name()}_lr{HYPERPARAMETERS['lr']}\"\n",
    "wandb.init(\n",
    "    entity=\"jassair\",\n",
    "    project=\"BaselineModel\",\n",
    "    name=RUN_NAME,\n",
    "    config=HYPERPARAMETERS,\n",
    ")\n",
    "wandb_logger = WandbLogger(project=\"BaselineModel\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "checkpoint_callback = L.pytorch.callbacks.ModelCheckpoint(\n",
    "    dirpath=\"./lightning_checkpoints\",\n",
    "    filename=RUN_NAME + \"-{epoch:02d}-{val_acc:.2f}\",\n",
    "    monitor=\"val_acc\",\n",
    "    save_last=True,\n",
    "    mode=\"max\"\n",
    ")"
   ],
   "id": "5321fed147ea27d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "early_stopping_callback = L.pytorch.callbacks.EarlyStopping(\n",
    "    monitor=\"val_acc\",\n",
    "    min_delta=0.005, # Increase accuracy by at least 0.5%\n",
    "    patience=10,\n",
    "    mode=\"max\"\n",
    ")"
   ],
   "id": "cb00b4fd467c9289"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58a360026f7265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/conda/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | model     | ResNet           | 23.6 M | train\n",
      "1 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "73.8 K    Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.6 M    Total params\n",
      "94.327    Total estimated model params size (MB)\n",
      "152       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0848b1fc1a04469cb30c7088c76f34fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e67de1aa6224bd2bb7093254e831d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d64b1a1a66476a85172e2d11abd3e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "    max_epochs=wandb.config.get(\"epochs\"),\n",
    "    accelerator=\"auto\",\n",
    "    logger=wandb_logger,\n",
    ")\n",
    "model = ImageClassifier(\n",
    "    wandb.config.get(\"lr\"), \n",
    "    wandb.config.get(\"ft_only\"),\n",
    "    wandb.config.get(\"wd\")\n",
    ")\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005ed038-3a61-4d52-b365-0d85427bc91f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
